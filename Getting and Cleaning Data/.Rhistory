z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
install.packages("codetools")
library(codetools)
findGlobals(h, merge=FALSE)[['variables']]
library(datasets)
data(iris)
?iris
iris
iris$Sepal.Length
iris$Sepal.Length[iris$Species == "virginica"]
mean(iris$Sepal.Length[iris$Species == "virginica"])
colMeans(iris)
apply(iris[,1:4], 1, mean)
apply(iris[,1:4], 2, mean)
data(mtcars)
summary(mtcars)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
with(mtcars, tapply(mpg, cyl, mean))
mean(mtcars$mpg, mtcars$cyl)
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
result <- tapply(mtcars$hp, mtcars$cyl, mean)
result
result[1] - result[3]
abs(result[1] - result[3])
debug(ls)
ls
k
ls
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
col <- 7:15
row <- 18:23
fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileurl, destfile = "gov.xlsx" )
library(xlsx)
dat <- read.xlsx('gov.xlsx', sheetIndex = 1, colIndex = col, rowIndex = row)
dat <- read.xlsx('gov.xlsx', sheetIndex = 1,
colIndex = col, rowIndex = row)
dat <- read.xlsx('gov.xlsx')
dat <- read.xlsx('gov.xlsx', sheetIndex = 1)
download.file(fileUrl, destfile='sample.xlsx', mode='wb')
fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile='sample.xlsx', mode='wb')
download.file(fileurl, destfile='sample.xlsx', mode='wb')
dat <- read.xlsx("sample.xlsx", sheetIndex = 1)
dat <- read.xlsx("sample.xlsx", sheetIndex = 1, colIndex = col, rowIndex = row)
sum(dat$Zip*dat$Ext,na.rm=T)
fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileurl, destfile='bal.xml', mode='wb')
XML
install.packages("XML")
library(XML)
doc <- xmlTreeParse(fileurl, useInternal = TRUE)
doc <- xmlTreeParse(fileurl)
rootNode <- xmlRoot("bal.xml")
doc <- xmlTreeParse(fileurl, useInternalNodes = TRUE)
?fread
fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileurl, destfile = "pw.csv", mode = "wb")
data <- fread("pw.csv")
install.packages("data.table")
library(data.table)
data <- fread("pw.csv")
View(data)
fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileurl, destfile = "pw.csv", mode = "wb")
data <- fread("pw.csv")
system.time(mean(DT$pwgtp15,by=DT$SEX))
DT <- fread("pw.csv")
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
install.packages("httr")
oauth_endpoints("github")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "0ec0bf2d6949ba0e5824",
secret = "dda969ebfb1e8deb182c88a8eb38c32e50f0035e")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
0
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
stop_for_status(req)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
myapp <- oauth_app("github",
key = "0ec0bf2d6949ba0e5824",
secret = "dda969ebfb1e8deb182c88a8eb38c32e50f0035e")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "0ec0bf2d6949ba0e5824",
secret = "246374638855372649dfc0566a7319d99b484f5d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
key = "18929132e7790585456a",
secret = "a9e821aa3e6fc6db464235f0b71def53832c6569")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
install.packages("httpuv")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "18929132e7790585456a",
secret = "a9e821aa3e6fc6db464235f0b71def53832c6569")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
install.packages("sqldf")
data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv")
data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",
destfile = "pwgtp1.csv", mode = "wb")
library(sqldf)
acs <- read.csv("pwgtp1")
acs <- read.csv("pwgtp1.csv")
library(sqldf)
sub <- sqldf("select * from acs where AGEP \lt< 50 and pwgtp1")
sub <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
sub2 <- sqldf("select pwgtp1 from acs where AGEP \lt< 50")
sub2 <- sqldf("select pwgtp1 from acs where AGEP < 50")
a <- acs$AGEP
b <- sqldf("select distinct AGEP from acs")
b <- sqldf("select unique AGEP from acs")
b <- sqldf("select AGEP where unique from acs")
unique(acs$AGEP)
u <- unique(acs$AGEP)
b <- sqldf("select AGEP where unique from acs")
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode
nchar(htmlCode[c(10,20,30,100)])
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "w", mode = "wb")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "w.for", mode = "wb")
data <- read.fwf("w.for")
data <- read.fwf("w.for", widths = 9)
View(data)
data <- read.fwf("w.for", widths = 4)
data <- read.fwf("w.for", widths = c(4,9))
View(data)
data <- read.fwf("w.for", widths = c(9,4))
data <- read.fwf("w.for", widths = 9)
View(data)
data <- read.fwf("w.for", widths = 1:9)
data <- read.fwf("w.for", skip = 4)
url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url, destfile = 'agri.csv', mode = "wb")
data <- read.csv("agri.csv")
names(data)
subdata <- data[,c("NP","ACR","AGS")]
head(subadata,5)
head(subdata,5)
?which
clean <- subdata[,subdata$ACR == 4 & subdata$AGS == 6]
clean <- subdata[subdata$ACR == 4 & subdata$AGS == 6]
clean <- subdata[subdata$ACR == 4 &&
subdata$AGS == 6]
clean <- subdata[,subdata$ACR == 4 &&
subdata$AGS == 6]
clean <- subdata[,subdata$ACR == 4 && subdata$AGS == 6]
clean <- subdata[,c(subdata$ACR == 4, subdata$AGS == 6)]
clean <- subdata[c(subdata$ACR == 4, subdata$AGS == 6)]
clean <- subdata[, subdata$ACR == 4 and subdata$AGS == 6]
clean <- subdata[, subdata$ACR == 4 & subdata$AGS == 6]
clean <- subdata$NP[, subdata$ACR == 4 & subdata$AGS == 6]
clean <- subdata$NP[, subdata$ACR == 4 && subdata$AGS == 6]
clean <- subdata[, subdata$ACR == 4 && subdata$AGS == 6]
View(clean)
clean <- subset(subdata, subdata$ACR == 4 && subdata$AGS == 6 )
clean <- subset(subdata, subdata$ACR == "4" && subdata$AGS == "6")
clean <- subset(subdata, ACR == 4  && AGS == 6)
clean <- subset(subdata, AGS == 6)
View(clean)
clean <- subset(subdata, ACR = 3 && AGS == 6)
View(clean)
clean <- subset(subdata, ACR = 3 & AGS == 6)
clean <- subdata[,subdata$ACR == 3 & subdata$AGS == 6]
clean <- subdata[,subdata$ACR == 3 && subdata$AGS == 6]
clean <- subdata[subdata$ACR == 3 & subdata$AGS == 6,]
View(clean)
clean <- subdata[subdata$ACR == 3 & subdata$AGS == 6, na.rm = TRUE]
clean <- subdata[subdata$ACR == 3 & subdata$AGS == 6]
clean ,- clean[!is.na(clean)]
clean <- clean[!is.na(clean)]
clean <- clean[!is.na(clean),]
clean <- clean[,!is.na(clean)]
clean <- subdata[subdata$ACR == 3 & subdata$AGS == 6,]
clean <- subdata[subdata$ACR == 3 & subdata$AGS == 6,]
clean <- na.omit(clean)
View(clean)
which(clean)
subdata <- na.omit(subdata)
clean <- subdata$ACR == 3 & subdata$AGS == 6,]
clean <- subdata$ACR == 3 & subdata$AGS == 6
which(clean)
View(subdata)
clean <- data$ACR == 3 & data$AGS == 6
a
which(clean)
install.packages("jpeg")
library(jpeg)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(url, destfile = "photo.jpg", mode = "wb")
a <- readJPEG("photo.jpg")
a <- readJPEG("photo.jpg", native = TRUE)
summary(a)
table(a, prob(0.30, 0.80))
table(a, c(0.30, 0.80))
quantile(a)
quantile(a, probs = c(0.30,0.80), na.rm = TRUE)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url, destfile = "product.csv", mode = "wb")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url, destfile = "education.csv", mode = "wb")
product <- read.csv("product.csv")
education <- read.csv("education.csv")
View(education)
View(product)
product <- read.table("product.csv")
product <- read.csv("product.csv")
View(product)
View(education)
View(education)
mergeDF <- merge(education, product, by.x = "CountryCode", by.y = "X")
View(mergeDF)
View(product)
mergeDF <- merge(education, product, by.x = "CountryCode", by.y = "X", all = TRUE)
mergeDF <- merge(education, product, by.x = "CountryCode", by.y = "X")
View(mergeDF)
View(education)
View(product)
names(product)
product <- product[,c(1,2,4,5)]
View(product)
product[238,]
product[236,]
product[product$X == "",]$X <- NA
View(product)
product2 <- na.omit(product)
View(product2)
mergeDF <- merge(education, product2, by.x = "CountryCode", by.y = "X")
mergeDF <- merge(product2, education, by.x = "X", by.y = "CountryCode")
View(mergeDF)
View(product2)
View(product2)
View(education)
education[education$Income.Group == "",]$Income.Group <- NA
education2 <- na.omit(education)
education2 <- na.omit(education$Income.Group)
education2 <- education[,!is.na(education$Income.Group)]
education2 <- education[!is.na(education$Income.Group),]
View(product2)
product[product$Gross.domestic.product.2012 == "",]$Gross.domestic.product.2012 <- NA
product2 <- product[,!is.na(product$Gross.domestic.product.2012)]
product2 <- product[!is.na(product$Gross.domestic.product.2012),]
mergeDF <- merge(product2, education, by.x = "X", by.y = "CountryCode")
View(mergeDF)
order(mergeDF, X3, decreasing = TRUE)
order(mergeDF, mergeDF$X3, decreasing = TRUE)
order(mergeDF, mergeDF$X3, decreasing = TRUE)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url, destfile = "product.csv", mode = "wb")
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url, destfile = "education.csv", mode = "wb")
product <- read.csv("product.csv")
education <- read.csv("education.csv")
View(education)
View(product)
product <- product[,c(1,2,4,5)]
View(product)
product <- product[1:235,]
View(product)
product[product$X.2 == ""]$X.2 <- NA
product[product$X.2 == "",]$X.2 <- NA
product <- na.omit(product)
n <- product[1,]
n
n
n <- product[3,]
n
n <- product[1,]
names(product) <- n
View(product)
View(n)
n <- as.vector(product[1,])
View(n)
n <- as.vector(product[1,1:4])
n <- as.array(n)
n <- as.vector(n)
n <- product[1,]
n <- as.vector(n)
n <- as.vector(n)
names(product) <- c("CountryCode","Ranking","Country", "GDP")
product2 <- product[-1,]
View(product2)
product <- product[-1,]
View(education)
mergeDF <- merge(product, education, by = "CountryCode")
View(mergeDF)
mergeDF2 <- mergeDF[order(mergeDF$GDP),]
View(mergeDF2)
rownames(mergeDF2) <- c(1:nrow(mergeDF2))
mergeDF2$GDP <- as.numeric(mergeDF2$GDP)
mergeDF2 <- mergeDF[order(mergeDF$GDP),]
install.packages("stringr")
library(stringr)
str <- str_replace_all(mergeDF2$GDP, pattern = ",", replacement = '""')
head(str,20)
str[2]
str <- str_replace_all(mergeDF2$GDP, pattern = ",", replacement = "")
str[2]
head(str,20)
mergeDF2$GDP <- str_replace_all(mergeDF2$GDP, pattern = ",", replacement = "")
mergeDF2$GDP <- as.numeric(mergeDF2$GDP)
mergeDF2 <- mergeDF[order(mergeDF$GDP),]
mergeDF2$GDP <- str_replace_all(mergeDF2$GDP, pattern = ",", replacement = "")
mergeDF2$GDP <- as.numeric(mergeDF2$GDP)
mergeDF2 <- mergeDF2[order(mergeDF$GDP),]
mergeDF2 <- mergeDF2[order(mergeDF$GDP),]
mergeDF2 <- mergeDF2[order(mergeDF$Ranking),]
View(mergeDF2)
mergeDF2 <- mergeDF2[,order(mergeDF$Ranking)]
mergeDF2 <- mergeDF2[order(mergeDF$Ranking),]
mergeDF2 <- mergeDF2[order(mergeDF2$Ranking),]
mergeDF2 <- mergeDF2[order(mergeDF2$GDP),]
rownames(mergeDF2) <- c(1:nrow(mergeDF2))
count <- is.na(mergeDF2$GDP)
sum(count)
count <- !is.na(mergeDF2$GDP)
sum(count)
mergeDF2[mergeDF2$Ranking == "",]$Ranking <- NA
count <- !is.na(mergeDF2$Ranking)
sum(count)
data <- mergeDF2[!is.na(mergeDF2$Ranking),]
View(data)
install.packages("dplyr")
library(dplyr)
income <- filter(data, Income.Group == "High income: OECD" | Income.Group == "High income: nonOECD")
View(income)
summarise(income)
summarise(income,mean)
OECD <- group_by(income, Income.Group)
summarise(mean = mean(Income.Group))
OECD <- group_by(income, Income.Group)
summarise(mean = mean(Income.Group))
OECD <- group_by(income, Income.Group)
summarise(Income.Group = mean(Income.Group))
OECD <- group_by(income, Income.Group)
summarise(mean = mean(GDP))
OECD <- group_by(income, Income.Group) %>%
summarise(mean = mean(GDP))
View(OECD)
OECD <- group_by(income, Income.Group) %>%
summarise(mean = mean(Ranking))
income$Ranking <- as.numeric(income$Ranking)
OECD <- group_by(income, Income.Group) %>%
summarise(mean = mean(Ranking))
OECD
View(OECD)
View(mergeDF2)
View(data)
View(OECD)
View(OECD)
View(income)
View(mergeDF)
View(income)
View(mergeDF2)
mergeDF2$Ranking <- as.numeric(mergeDF2$Ranking)
mergeDF2 <- mergeDF2[order(mergeDF2$Ranking),]
mergeDF2 <- mergeDF2[order(mergeDF2$GDP),]
View(data)
data$Ranking <- as.numeric(income$data)
data$Ranking <- as.numeric(data$Ranking)
OECD <- group_by(data, Income.Group) %>%
summarise(mean = mean(Ranking))
View(OECD)
View(data)
data$Ranking <- 1:nrow(data)
data$Ranking <- nrow(data):1
OECD <- group_by(data, Income.Group) %>%
summarise(mean = mean(Ranking))
View(OECD)
data$Ranking <- cut(data$Ranking, breaks = quantile(data$Ranking))
table(data$Ranking, data$Income.Group)
data$GDP <- as.numeric(data$GDP)
table(data$Ranking, data$Income.Group)
data$Ranking <- cut2(data$Ranking, g=5))
data$Ranking <- cut2(data$Ranking, g=5)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
data$Ranking <- cut2(data$Ranking, g=5)
table(data$Ranking, data$Income.Group)
data$Ranking <- cut(data$Ranking, breaks = c(0.20, 0.40, 0.60, 0.80))
data$Ranking <- cut(data$Ranking, breaks = quantile(data$Ranking, prob = c(0.20, 0.40, 0.60, 0.80)))
data$Ranking <- cut(data$Ranking, breaks = quantile(data$Ranking)
table(data$Ranking, data$Income.Group)
table(data$Ranking, data$Income.Group)
f5 <- filter(data, Income.Group == "Lower middle income")
View(f5)
View(mergeDF2)
f5 <- filter(mergeDF2, Income.Group == "Lower middle income")
View(f5)
f5 <- f5[order(f5$Ranking),]
View(data)
View(mergeDF)
f5 <- filter(mergeDF, Income.Group == "Lower middle income")
f5 <- f5[order(f5$Ranking),]
f5$Ranking <- as.numeric(f5$Ranking)
f5 <- f5[order(f5$Ranking),]
f5 <- filter(mergeDF, Income.Group == "Lower middle income")
View(github_token)
View(req)
clearConsole()
View(github_token)
ls()
rm(list = ls())
setwd("C:/Users/Keita/DataScience/Getting and Cleaning Data")
#Set the working directory where the dataset file is located
#Read activity labels and features
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")
features <- read.table("./UCI HAR Dataset/features.txt")
#Loading packages
library(dplyr)
#Test set
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt", col.names = features[,2])
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt", col.names = "activity_number")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt", col.names = "subject")
tag_test <- data.frame(tag = rep("test",length = nrow(subject_test)))
test_set <- data.frame(tag_test,subject_test, y_test, X_test)
#Trauin set
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt", col.names = features[,2])
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt", col.names = "activity_number")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt", col.names = "subject")
tag_train <- data.frame(tag = rep("train",length = nrow(subject_train)))
train_set <- data.frame(tag_train,subject_train, y_train, X_train)
#Merge test and training datas
mergeDF <- merge(test_set, train_set, all = TRUE)
#Adding activity labels
mergeDF <- mergeDF %>%
mutate(activity_name = factor(activity_number,
levels = activity_labels[,1],
labels = activity_labels[,2]))
#Loading mesurements (Test set)
test_txt_list <- list.files(path = "./UCI HAR Dataset/test/Inertial Signals", full.name = TRUE)
test_txt_name <- list.files(path = "./UCI HAR Dataset/test/Inertial Signals", full.name = FALSE)
test_txt_name <- gsub(".txt$","",test_txt_name)
test_list <- tapply(test_txt_list, list(test_txt_name), read.table)
CalculateMeanByRow <- function(df) apply(df, 1, mean)
CalculateSDByRow <- function(df) apply(df, 1, sd)
#Calculating mean of each mesurement (Test set)
mean_test_matrix <- sapply(test_list, CalculateMeanByRow)
mean_test <- as.data.frame(mean_test_matrix)
#Calculating standard deviation of each mesurement (Test set)
sd_test_matrix <- sapply(test_list, CalculateSDByRow)
sd_test <- as.data.frame(sd_test_matrix)
#Loading mesurements (Train set)
train_txt_list <- list.files(path = "./UCI HAR Dataset/train/Inertial Signals", full.name = TRUE)
train_txt_name <- list.files(path = "./UCI HAR Dataset/train/Inertial Signals", full.name = FALSE)
train_txt_name <- gsub(".txt$","",train_txt_name)
train_list <- tapply(train_txt_list, list(train_txt_name), read.table)
#Calculating mean of each mesurement (Test set)
mean_train_matrix <- sapply(train_list, CalculateMeanByRow)
mean_train <- as.data.frame(mean_train_matrix)
#Calculating standard deviation of each mesurement (Test set)
sd_train_matrix <- sapply(train_list, CalculateSDByRow)
sd_train <- as.data.frame(sd_train_matrix)
#Binding all mesurements
mesurement_labels <- gsub("_test$","",test_txt_name)
mean_labels <- paste("mean_", mesurement_labels, sep = "")
sd_labels <- paste("sd_", mesurement_labels, sep = "")
colnames(mean_test) <- mean_labels
colnames(sd_test) <- sd_labels
colnames(mean_train) <- mean_labels
colnames(sd_train) <- sd_labels
mean_mesurements <- rbind(mean_test, mean_train)
sd_mesurements <- rbind(sd_test, sd_train)
#Create a dataset with all dataframes
dataset <- cbind(mergeDF,mean_mesurements,sd_mesurements)
#tidy data set with the average of each variable for each activity and each subject.
averagedataset_by_activity <- dataset %>%
group_by(activity_name) %>%
summarise_if(is.numeric, funs(mean))
averagedataset_by_activity <- averagedataset_by_activity[,-c(2:3)]
averagedataset_by_subject <- dataset %>%
group_by(subject) %>%
summarise_if(is.numeric, funs(mean))
averagedataset_by_subject <- averagedataset_by_subject[,-2]
write.table(averagedataset_by_activity, file = "Average_dataset_by_activity.txt", row.names = FALSE)
View(averagedataset_by_subject)
tidydataset <- dataset %>%
group_by(activity_name, subject) %>%
summarise_if(is.numeric, funs(mean))
View(tidydataset)
summary(tidydataset)
View(tidydataset)
write.table(tidydataset, file = "tidydataset.txt", row.names = FALSE)
